name: AI Config Validation

on:
  pull_request:
    branches: [main]
  push:
    branches: [main, enable-ai-config-tests]
  workflow_dispatch:
    inputs:
      environment:
        description: 'LaunchDarkly environment to validate against'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

jobs:
  validate-configs:
    name: Validate AI Configs
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"
          enable-cache: true
          cache-dependency-glob: "**/pyproject.toml"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: |
          uv venv
          # Install dependencies without installing the package itself (to avoid dev dependency issues)
          uv pip install langchain langgraph langchain-anthropic fastapi "uvicorn[standard]" pydantic launchdarkly-server-sdk launchdarkly-server-sdk-ai numpy openai faiss-cpu PyMuPDF tiktoken streamlit requests python-dotenv PyYAML langchain-openai langchain-mcp-adapters beautifulsoup4 mcp semanticscholar rank-bm25 langchain-mistralai httpx
          uv pip install git+https://x-access-token:${{ secrets.GH_PAT }}@github.com/launchdarkly-labs/scarlett_ai_configs_ci_cd-.git@feature/initial-implementation

      - name: Validate required secrets
        run: |
          if [ -z "${{ secrets.LD_SDK_KEY }}" ]; then
            echo "::error::Missing required secret: LD_SDK_KEY"
            exit 1
          fi
          if [ -z "${{ secrets.LD_API_KEY }}" ]; then
            echo "::error::Missing required secret: LD_API_KEY"
            exit 1
          fi
          echo "‚úÖ Required secrets are configured"

      - name: Run AI Config validation
        env:
          LD_SDK_KEY: ${{ secrets.LD_SDK_KEY }}
          LD_API_KEY: ${{ secrets.LD_API_KEY }}
          LD_PROJECT_KEY: ${{ secrets.LD_PROJECT_KEY }}
        run: |
          # Use ld-aic-cicd framework to validate our AI configs
          .venv/bin/ld-aic validate \
            --environment ${{ github.event.inputs.environment || 'production' }} \
            --config-keys "supervisor-agent,support-agent,security-agent" \
            --report validation-report.json \
            --fail-on-error

      - name: Upload validation report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: validation-report.json

      - name: Comment PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('validation-report.json', 'utf8'));

            let comment = '## üîç AI Config Validation Results\n\n';
            comment += `**Environment:** ${report.environment}\n`;
            comment += `**Total Configs:** ${report.total_configs}\n\n`;

            // Count statuses
            const configs = Object.values(report.configs);
            const valid = configs.filter(c => c.valid).length;
            const errors = configs.filter(c => c.errors.length > 0).length;
            const warnings = configs.filter(c => c.warnings.length > 0).length;

            // Summary
            comment += '### Summary\n';
            comment += `‚úÖ Valid: ${valid}\n`;
            comment += `‚ùå Errors: ${errors}\n`;
            comment += `‚ö†Ô∏è Warnings: ${warnings}\n\n`;

            // Details for problematic configs
            if (errors > 0 || warnings > 0) {
              comment += '### Issues Found\n';
              for (const [key, config] of Object.entries(report.configs)) {
                if (config.errors.length > 0 || config.warnings.length > 0) {
                  comment += `\n**${key}**\n`;
                  config.errors.forEach(e => comment += `- ‚ùå ${e}\n`);
                  config.warnings.forEach(w => comment += `- ‚ö†Ô∏è ${w}\n`);
                }
              }
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  evaluate-configs:
    name: Evaluate AI Configs with Judge
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"
          enable-cache: true
          cache-dependency-glob: "**/pyproject.toml"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: |
          uv venv
          # Install dependencies without installing the package itself (to avoid dev dependency issues)
          uv pip install langchain langgraph langchain-anthropic fastapi "uvicorn[standard]" pydantic launchdarkly-server-sdk launchdarkly-server-sdk-ai numpy openai faiss-cpu PyMuPDF tiktoken streamlit requests python-dotenv PyYAML langchain-openai langchain-mcp-adapters beautifulsoup4 mcp semanticscholar rank-bm25 langchain-mistralai httpx
          uv pip install git+https://x-access-token:${{ secrets.GH_PAT }}@github.com/launchdarkly-labs/scarlett_ai_configs_ci_cd-.git@feature/initial-implementation

      - name: Validate required secrets
        run: |
          # Check LaunchDarkly secrets
          if [ -z "${{ secrets.LD_SDK_KEY }}" ]; then
            echo "::error::Missing required secret: LD_SDK_KEY"
            exit 1
          fi

          # Check at least one AI provider API key is set
          if [ -z "${{ secrets.OPENAI_API_KEY }}" ] && [ -z "${{ secrets.ANTHROPIC_API_KEY }}" ]; then
            echo "::error::At least one AI provider API key required: OPENAI_API_KEY or ANTHROPIC_API_KEY"
            exit 1
          fi

          echo "‚úÖ Required secrets are configured"

      - name: Initialize vector embeddings
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          echo "üìö Initializing vector embeddings for search tools..."
          .venv/bin/python initialize_embeddings.py

      - name: Run tests with API
        env:
          LD_SDK_KEY: ${{ secrets.LD_SDK_KEY }}
          LD_API_KEY: ${{ secrets.LD_API_KEY }}
          LD_PROJECT_KEY: ${{ secrets.LD_PROJECT_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
          PYTHONPATH: ${{ github.workspace }}
          CI_SAFE_MODE: true
        run: |
          # NOTE: The evaluator (evaluators/local_evaluator.py) expects the API on port 8000
          # If you change the port here, update the port in the evaluator as well
          echo "üöÄ Starting agents-demo API on port 8000..."
          .venv/bin/python -m uvicorn api.main:app --host 0.0.0.0 --port 8000 > /tmp/agents-demo-api.log 2>&1 &
          API_PID=$!

          # Wait for API to be ready (max 30 seconds)
          echo "Waiting for API to start..."
          for i in {1..30}; do
            if curl -s http://localhost:8000/health >/dev/null 2>&1; then
              echo "‚úÖ API is ready!"
              break
            fi
            if ! kill -0 $API_PID 2>/dev/null; then
              echo "‚ùå API process died. Logs:"
              cat /tmp/agents-demo-api.log
              exit 1
            fi
            sleep 1
          done

          # Test the /chat endpoint with curl
          echo "üîç Testing /chat endpoint with curl..."
          curl -X POST http://localhost:8000/chat \
            -H "Content-Type: application/json" \
            -d '{"message":"test","user_id":"test-user","user_context":{}}' \
            || echo "Curl test failed"

          # Test with httpx (Python)
          echo "üêç Testing /chat endpoint with httpx..."
          .venv/bin/python << 'PYTHON_SCRIPT'
          import httpx
          import asyncio

          async def test():
              client = httpx.AsyncClient(timeout=10.0)
              try:
                  response = await client.post(
                      'http://127.0.0.1:8000/chat',
                      json={'message': 'test', 'user_id': 'test-user', 'user_context': {}}
                  )
                  print(f'HTTPx test - Status: {response.status_code}')
                  print(f'HTTPx test - Response length: {len(response.text)}')
                  data = response.json()
                  print(f'HTTPx test - Has response field: {"response" in data}')
              except Exception as e:
                  print(f'HTTPx test FAILED: {type(e).__name__}: {str(e)}')
                  import traceback
                  traceback.print_exc()
              finally:
                  await client.aclose()

          asyncio.run(test())
          PYTHON_SCRIPT

          echo "üß™ Running AI Config test suite with judge evaluations..."
          echo "Working directory: $(pwd)"
          echo "Test data file exists: $(test -f test_data/ai_config_evaluation.yaml && echo 'YES' || echo 'NO')"
          
          # Export all env vars so they're inherited by subprocesses
          export LD_SDK_KEY="${LD_SDK_KEY}"
          export LD_API_KEY="${LD_API_KEY}"
          export LD_PROJECT_KEY="${LD_PROJECT_KEY}"
          export ANTHROPIC_API_KEY="${ANTHROPIC_API_KEY}"
          export OPENAI_API_KEY="${OPENAI_API_KEY}"
          export MISTRAL_API_KEY="${MISTRAL_API_KEY}"
          export CI_SAFE_MODE="${CI_SAFE_MODE}"
          
          # Debug: verify env vars are set
          echo "üîç Env vars check:"
          echo "  LD_SDK_KEY: ${LD_SDK_KEY:0:10}... (${#LD_SDK_KEY} chars)"
          echo "  ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:+SET}"
          echo "  OPENAI_API_KEY: ${OPENAI_API_KEY:+SET}"
          echo "  MISTRAL_API_KEY: ${MISTRAL_API_KEY:+SET}"
          
          .venv/bin/ld-aic test \
            --config-keys "supervisor-agent,support-agent,security-agent" \
            --environment production \
            --evaluation-dataset test_data/ai_config_evaluation.yaml \
            --evaluator evaluators.local_evaluator:AgentsDemoEvaluator \
            --threshold 7.0 \
            --report test-report.json \
            --skip-sync

          TEST_EXIT_CODE=$?

          echo "üõë Stopping API..."
          kill $API_PID 2>/dev/null || true

          # If tests failed, dump API logs for debugging
          if [ $TEST_EXIT_CODE -ne 0 ]; then
            echo "===== /tmp/agents-demo-api.log ====="
            if [ -f /tmp/agents-demo-api.log ]; then
              tail -n 500 /tmp/agents-demo-api.log || true
            else
              echo "No API log found at /tmp/agents-demo-api.log"
            fi
          fi

          exit $TEST_EXIT_CODE

      - name: Upload test report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-report
          path: test-report.json

      - name: Upload judge evaluation logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: judge-evaluation-logs
          path: logs/judge_evaluations/**

      - name: Upload API server log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: api-server-log
          path: /tmp/agents-demo-api.log

  sync-production:
    name: Sync Production Configs
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"
          enable-cache: true
          cache-dependency-glob: "**/pyproject.toml"

      - name: Set up Python
        run: uv python install

      - name: Install dependencies
        run: |
          uv venv
          # Install dependencies without installing the package itself (to avoid dev dependency issues)
          uv pip install langchain langgraph langchain-anthropic fastapi "uvicorn[standard]" pydantic launchdarkly-server-sdk launchdarkly-server-sdk-ai numpy openai faiss-cpu PyMuPDF tiktoken streamlit requests python-dotenv PyYAML langchain-openai langchain-mcp-adapters beautifulsoup4 mcp semanticscholar rank-bm25 langchain-mistralai httpx
          uv pip install git+https://x-access-token:${{ secrets.GH_PAT }}@github.com/launchdarkly-labs/scarlett_ai_configs_ci_cd-.git@feature/initial-implementation

      - name: Validate required secrets
        run: |
          if [ -z "${{ secrets.LD_API_KEY }}" ]; then
            echo "::error::Missing required secret: LD_API_KEY"
            exit 1
          fi
          if [ -z "${{ secrets.LD_PROJECT_KEY }}" ]; then
            echo "::error::Missing required secret: LD_PROJECT_KEY"
            exit 1
          fi
          echo "‚úÖ Required secrets are configured"

      - name: Sync production configs
        env:
          LD_API_KEY: ${{ secrets.LD_API_KEY }}
          LD_PROJECT_KEY: ${{ secrets.LD_PROJECT_KEY }}
        run: |
          mkdir -p configs
          .venv/bin/ld-aic sync \
            --environment production \
            --output-dir configs \
            --format json \
            --generate-module

      - name: Check for drift
        run: |
          # Check if there are changes to commit
          git diff --exit-code configs/ || echo "DRIFT_DETECTED=true" >> $GITHUB_ENV

      - name: Create PR for config updates
        if: env.DRIFT_DETECTED == 'true'
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: 'Sync AI configs from production'
          title: 'Sync AI Configs from Production'
          body: |
            ## üîÑ Production Config Sync

            This PR updates the local AI config defaults to match production.

            ### AI Configs Synced
            - `supervisor-agent` - Multi-agent workflow orchestration
            - `support-agent` - RAG + MCP research capabilities
            - `security-agent` - PII detection and compliance

            ### Changes
            - Updated config snapshots in `configs/`
            - Regenerated `configs/production_defaults.py`

            Please review the changes to ensure they are expected.
          branch: sync/production-configs
          delete-branch: true
